	The ability to protect privacy in open data is a challenging obstacle for our society in light of the many breaches of privacy in technology in the last few years. Even when a malevolent intention is not present, non-profits such as Wikileaks illustrate how easy it is to access documents online that are meant to be kept confidential, by demonstrating that 3rd parties have the ability to publish secret information and classified media from anonymous sources. While the issue we deal with this week is in respect to information collected about users of apps and services, the issues that arise when access to information on people is at risk brings much stronger concerns to light. 
In this day and age, people are spending hours a day online, either on their computers, phones, ipads, etc., using programs which are collecting data about their users. In Broken Promises of Privacy: Responding to the Suppressing Failure of Anonymization, Paul Ohm discusses how companies that collect information on users try to make the information secret through a process termed anonymization. He points out how government officials, companies like Google, and other technologically advanced  parties are in agreement that anonymization of data is a safe way to maintain privacy. His article sets out to conducts a nuanced analysis of the privacy issues facing our society in regards to information collected on users, and illustrates the flaws that accompany companies efforts to anonymize information by deleting information like social security numbers, names, and other identifying information. In response to the issues he finds with anonymization, he offers an alternative way of collecting data to ensure consumer privacy after pointing out the problems. My thoughts are that the confidence instilled in anonymization by these parties does not come from ignorance of its problems, but rather from an acceptance that it is most likely impossible to preserve secrecy in an open data setting. 
	Ohm’s essay brings legitimate concerns to light regarding the anonymization policy, and shows how many parties are willing to look the other way in regards to flaws in the process. In response to Ohm’s concerns, I believe one of the underlying issues here may be that those in favor of anonymization may not actually think anonymization is the best way of maintaining privacy, but rather that anonymization does a good enough job to satisfy the public. The real issue here may be that there is no way to make data completely anonymous. Ohm’s article may actually highlight that companies and government officials think anonymization does a good enough job in keeping most information private by making it challenging for the average person to access information, and the cost of a small chance of a security breach is worth the benefit of providing data. The support provided by technologically advanced companies and officials supporting the anonymization process makes me wonder whether the support is provided not because these people and groups believe that anonymization is the best method of protecting privacy, but rather because they do not believe a completely effective method actually exists, and that they think anonymization is the most adequate system of providing data in a secured setting. 
	Despite how terrifying Ohm’s examples of data being used to identify people appears, I am concerned that the risk of invasion of privacy is a risk that will never be eliminated. The example Ohm provides of Latanya Sweeney, a professor of computer science, who discovered that 87.1 percent of people in the United States were uniquely identified by their zip code, birth date, and sex sheds light on the inadequacies of the anonymization process, and helps us understand basic precautions companies can pursue to reduce privacy invasion. However in light of my interpretation, while Ohm shows there is definitely room for improvement in terms of anonymisation, I wonder if the invasion of privacy is a risk of open government data that we as a society will be forced to accept. While I believe the author has provided strong ways of improving privacy, and has identified a stronger approach to provide protections, I am not convinced that any method will result in an airtight method of preserving privacy. Despite my concerns, what remains important is that scholars, academics, and other interested parties continue to investigate and improve the system, such as Ohm in search of making the privacy protections as close to airtight as humanly possible. 
	I am further convinced that there is no airtight solution to privacy when reading the article Fool’s Gold. In Fool’s Gold, the authors’ premise is that this method of privacy can support data research without sacrificing privacy, but the article shows that differential privacy offers useless privacy protections and wrong research results. They argue that differential privacy should be used only in limited situations where it is well suited to the task at hand, but in the majority of other situations, other methods should be used. My thoughts on this article are that people think that there is an answer out there to privacy issues, and there is a solution to providing open data in a secured setting, however it may be the case that there really is no solid solution and access to government data will have to come at the costs of reduced privacy. This may not be easy for us to live with, however it is a choice our society is forced to make. 
